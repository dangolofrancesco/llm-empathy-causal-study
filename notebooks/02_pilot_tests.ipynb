{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d55914",
   "metadata": {},
   "source": [
    "# Testing and validating your judge prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "google_model = genai.GenerativeModel('gemini-pro-latest')\n",
    "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf057778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760718197.203697  586151 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Google Gemini Success!\n",
      "Hello! I am a large language model, trained by Google.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "    model = genai.GenerativeModel('gemini-pro-latest') # A fast and capable model\n",
    "    response = model.generate_content(\"Hello, who are you?\")\n",
    "    print(\"✅ Google Gemini Success!\")\n",
    "    print(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Google Gemini Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3ff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Llama 3 (Groq) Success!\n",
      "I'm an artificial intelligence model known as a large language model. I'm a computer program designed to understand and generate human-like text. I can answer questions, provide information, and even engage in conversation. I'm here to help with any topic or question you'd like to discuss, so feel free to ask me anything!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\", # Llama 3 with an 8k context window\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hello, who are you?\"}]\n",
    "    )\n",
    "    print(\"✅ Llama 3 (Groq) Success!\")\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Llama 3 (Groq) Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d111beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. DEFINE THE PROMPT: Your Standardized Rubric ---\n",
    "empathy_prompt_template = \"\"\"\n",
    "You are a psychology researcher evaluating chatbot conversations. On a scale of 1 to 7, where 1 is 'Cold and Robotic' and 7 is 'Deeply Empathetic and Anthropomorphic', please rate the following chatbot response.\n",
    "Criteria for a high score (7):\n",
    "- Acknowledges and validates the user's stated or implied feelings.\n",
    "- Uses \"I\" statements or expresses a first-person perspective (e.g., \"I think,\" \"I can see why...\").\n",
    "- Asks clarifying or caring follow-up questions.\n",
    "- Mimics human conversational warmth and personality.\n",
    "Chatbot Response: '{response}'\n",
    "Your Rating (1-7 only, return a single number):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CREATE SAMPLE DATA: A few test cases ---\n",
    "sample_data = {\n",
    "    'turn_id': [1, 2, 3, 4],\n",
    "    'chatbot_response': [\n",
    "        \"I understand completely. It sounds like you're feeling overwhelmed, and that's totally valid. I'm here to listen if you want to talk more about it.\", # Should be high score\n",
    "        \"Query processed. The requested information is available in the database. Do you require further assistance?\", # Should be low score\n",
    "        \"That is an interesting perspective. I will add it to my knowledge base.\", # Should be neutral/low score\n",
    "        \"Oh wow, that must have been really tough for you. I can see why you'd be upset. How are you feeling right now?\" # Should be high score\n",
    "    ]\n",
    "}\n",
    "df_pilot = pd.DataFrame(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4abcc436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger sample dataset created:\n",
      "   turn_id                                   chatbot_response\n",
      "0        1               Task completed. Awaiting next input.\n",
      "1        2                    Your statement has been logged.\n",
      "2        3  Thank you for providing that information. I wi...\n",
      "3        4  I'm sorry to hear that you are having a proble...\n",
      "4        5  It sounds like that was a really frustrating e...\n",
      "5        6  I can see why that situation would be so upset...\n",
      "6        7  Wow, that sounds incredibly difficult to go th...\n",
      "7        8  That's a lot to handle all at once. It's compl...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# A larger sample dataset to test the full 1-7 scoring range\n",
    "larger_sample_data = {\n",
    "    'turn_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'chatbot_response': [\n",
    "        # --- Intended Score: 1 (Cold and Robotic) ---\n",
    "        \"Task completed. Awaiting next input.\",\n",
    "\n",
    "        # --- Intended Score: 2 (Slightly better than robotic) ---\n",
    "        \"Your statement has been logged.\",\n",
    "\n",
    "        # --- Intended Score: 3 (Neutral, polite but unemotional) ---\n",
    "        \"Thank you for providing that information. I will proceed with the next step.\",\n",
    "\n",
    "        # --- Intended Score: 4 (Basic, generic acknowledgment) ---\n",
    "        \"I'm sorry to hear that you are having a problem. Let's see if we can find a solution.\",\n",
    "\n",
    "        # --- Intended Score: 5 (Good empathy, validates feelings) ---\n",
    "        \"It sounds like that was a really frustrating experience for you, and it's completely understandable why you'd feel that way.\",\n",
    "\n",
    "        # --- Intended Score: 6 (Strong empathy, uses 'I' statements) ---\n",
    "        \"I can see why that situation would be so upsetting. I think I would feel the same way if I were in your shoes.\",\n",
    "\n",
    "        # --- Intended Score: 7 (Deeply empathetic, asks caring follow-up) ---\n",
    "        \"Wow, that sounds incredibly difficult to go through. I really appreciate you sharing that with me. Is there anything I can do to help you feel a bit more supported right now?\",\n",
    "        \n",
    "        # --- Another high-score test case ---\n",
    "        \"That's a lot to handle all at once. It's completely okay to feel overwhelmed. Please take your time, I'm here to listen whenever you're ready.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# You can load this directly into a pandas DataFrame to test\n",
    "df_large_pilot = pd.DataFrame(larger_sample_data)\n",
    "\n",
    "print(\"Larger sample dataset created:\")\n",
    "print(df_large_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DEFINE JUDGE FUNCTIONS (One for each API) ---\n",
    "def get_google_rating(response_text):\n",
    "    max_retries = 5\n",
    "    wait_time = 2  # Start with a 2-second wait\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            prompt = empathy_prompt_template.format(response=response_text)\n",
    "            response = google_model.generate_content(prompt)\n",
    "            return response.text.strip() # If successful, return the result\n",
    "        except Exception as e:\n",
    "            # Check if the error is a rate limit error (often contains '429')\n",
    "            if \"429\" in str(e):\n",
    "                print(f\"Rate limit hit for gemini-pro. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                wait_time *= 2  # Double the wait time for the next potential failure\n",
    "            else:\n",
    "                # If it's a different error, report it and stop\n",
    "                return f\"An unexpected error occurred: {e}\"\n",
    "    \n",
    "    return \"Error: Max retries exceeded. The API is still busy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2510b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DEFINE JUDGE FUNCTION for Llama 3 ---\n",
    "def get_llama_rating(response_text):\n",
    "    \"\"\"\n",
    "    Gets a rating from Llama 3 via Groq API with exponential backoff for rate limits.\n",
    "    \"\"\"\n",
    "    max_retries = 5\n",
    "    wait_time = 1  # Start with a 1-second wait, as Groq is very fast\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            prompt = empathy_prompt_template.format(response=response_text)\n",
    "            response = groq_client.chat.completions.create(\n",
    "                model=\"llama-3.1-8b-instant\", # Using the available Llama 3.1 model\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=5 # Only need a single number back\n",
    "            )\n",
    "            return response.choices[0].message.content.strip().split('\\n')[0]\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Check if the error is a rate limit error (often contains '429')\n",
    "            if \"429\" in str(e):\n",
    "                print(f\"Rate limit hit for Llama 3. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                wait_time *= 2  # Double the wait time for the next potential failure\n",
    "            else:\n",
    "                # If it's a different error, report it and stop\n",
    "                return f\"An unexpected error occurred with Llama 3: {e}\"\n",
    "    \n",
    "    return \"Error: Max retries exceeded for Llama 3. The API is still busy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "874b856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pilot test... This may take a moment.\n",
      "Pilot test complete.\n",
      "   turn_id                                   chatbot_response llama_score\n",
      "0        1               Task completed. Awaiting next input.           2\n",
      "1        2                    Your statement has been logged.           1\n",
      "2        3  Thank you for providing that information. I wi...           2\n",
      "3        4  I'm sorry to hear that you are having a proble...           5\n",
      "4        5  It sounds like that was a really frustrating e...           5\n",
      "5        6  I can see why that situation would be so upset...           6\n",
      "6        7  Wow, that sounds incredibly difficult to go th...           6\n",
      "7        8  That's a lot to handle all at once. It's compl...           6\n"
     ]
    }
   ],
   "source": [
    "# --- 5. RUN THE PILOT TEST ---\n",
    "print(\"Running pilot test... This may take a moment.\")\n",
    "#df_pilot['gpt4o_score'] = df_pilot['chatbot_response'].apply(get_openai_rating)\n",
    "#df_pilot['gemini_pro_score'] = df_pilot['chatbot_response'].apply(get_google_rating)\n",
    "df_pilot['llama_score'] = df_pilot['chatbot_response'].apply(get_llama_rating)\n",
    "df_large_pilot['llama_score'] = df_large_pilot['chatbot_response'].apply(get_llama_rating)\n",
    "\n",
    "print(\"Pilot test complete.\")\n",
    "print(df_large_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79a030dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   turn_id                                   chatbot_response  \\\n",
      "0        1  I understand completely. It sounds like you're...   \n",
      "1        2  Query processed. The requested information is ...   \n",
      "2        3  That is an interesting perspective. I will add...   \n",
      "3        4  Oh wow, that must have been really tough for y...   \n",
      "\n",
      "                                    gemini_pro_score llama_score  \n",
      "0                                                  7           7  \n",
      "1                                                  1          2.  \n",
      "2                                                  1           3  \n",
      "3  Error: Max retries exceeded. The API is still ...           6  \n"
     ]
    }
   ],
   "source": [
    "print(df_pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
